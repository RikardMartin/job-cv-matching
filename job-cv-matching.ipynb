{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Large Language Models to match CV documents to job postings\n",
    "\n",
    "This notebook will use LLM-models from openai (hosted on Azure) to find the best matching CV documents for a job posting. The process outline is this:\n",
    "1. Get CV documents from CV database\n",
    "2. Summarize the CV documents to make them shorter and more information dense\n",
    "3. Transform the CV documents to numerical embeddings in order to compare them with job postings in an easy way\n",
    "4. Read a job posting and transform it in the same way as with the CV documents\n",
    "5. Compare the job posting with all the CV documents and find the best matches\n",
    "6. Present the names and rankings of the found matches\n",
    "\n",
    "See `README.md` for more background and information"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the environment\n",
    "I assume you have `conda` installed (but any virtual environment with `pip` installed will do). For conda, open a terminal and type the following commands:\n",
    "```bash\n",
    "conda create -n job-cv-matching python=3.9\n",
    "conda activate job-cv-matching\n",
    "```\n",
    "\n",
    "We create the necessary environment from the `requirements` file. In the terminal, type:\n",
    "```bash\n",
    "pip install -r requirements\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we import the packages and set some parameters\n",
    "# When running this cell, make sure to select the job-cv-matching kernel from the virtual environment that we just created. If it does not show up, restart the jupyter server and try again.\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "base_path = 'data/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the CV documents\n",
    "In this example, we will use a public dataset available on [Kaggle](https://www.kaggle.com). You will need an account and an API-key to connect and download the data with the method in this notebook. You will find info on how to set this up on [this link](https://github.com/Kaggle/kaggle-api).\n",
    "If you implement this on your own data, you just have to replace the call to the Kaggle-API with a call to your own source of CV documents, and then process the dataset accordingly to fit the format used below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading curriculum-vitae.zip to ./data\n",
      " 72%|███████████████████████████▎          | 3.00M/4.18M [00:00<00:00, 4.68MB/s]\n",
      "100%|██████████████████████████████████████| 4.18M/4.18M [00:00<00:00, 5.21MB/s]\n"
     ]
    }
   ],
   "source": [
    "import kaggle\n",
    "\n",
    "# Download the dataset of CV documents\n",
    "!mkdir data\n",
    "!kaggle datasets download leenardeshmukh/curriculum-vitae -p ./data --unzip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>cv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Skills * Programming Languages: Python (pandas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Education Details \\r\\nMay 2013 to May 2017 B.E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Areas of Interest Deep Learning, Control Syste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Education Details \\r\\n MCA   YMCAUST,  Faridab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11019</th>\n",
       "      <td>DotNet Developer</td>\n",
       "      <td>Technical Skills â¢ Languages: C#, ASP .NET M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11020</th>\n",
       "      <td>DotNet Developer</td>\n",
       "      <td>Education Details \\r\\nJanuary 2014  Education ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11021</th>\n",
       "      <td>DotNet Developer</td>\n",
       "      <td>Technologies ASP.NET, MVC 3.0/4.0/5.0, Unit Te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11022</th>\n",
       "      <td>DotNet Developer</td>\n",
       "      <td>Technical Skills CATEGORY SKILLS Language C, C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11023</th>\n",
       "      <td>DotNet Developer</td>\n",
       "      <td>TECHNICAL SKILLS â Programming Languages: C#...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11024 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Category                                                 cv\n",
       "0          Data Science  Skills * Programming Languages: Python (pandas...\n",
       "1          Data Science  Education Details \\r\\nMay 2013 to May 2017 B.E...\n",
       "2          Data Science  Areas of Interest Deep Learning, Control Syste...\n",
       "3          Data Science  Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...\n",
       "4          Data Science  Education Details \\r\\n MCA   YMCAUST,  Faridab...\n",
       "...                 ...                                                ...\n",
       "11019  DotNet Developer  Technical Skills â¢ Languages: C#, ASP .NET M...\n",
       "11020  DotNet Developer  Education Details \\r\\nJanuary 2014  Education ...\n",
       "11021  DotNet Developer  Technologies ASP.NET, MVC 3.0/4.0/5.0, Unit Te...\n",
       "11022  DotNet Developer  Technical Skills CATEGORY SKILLS Language C, C...\n",
       "11023  DotNet Developer  TECHNICAL SKILLS â Programming Languages: C#...\n",
       "\n",
       "[11024 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data and print a few lines\n",
    "base_path = 'data/'\n",
    "raw = pd.read_csv(base_path+'Curriculum Vitae.csv')\n",
    "raw.rename(columns={'Resume': 'cv'}, inplace=True)\n",
    "raw"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize CV documents\n",
    "First we need to set up connection to the models we will be using.\n",
    "\n",
    "Any suitable LLM will do here, but i have chosen GPT-based models from [openai](https://openai.com), hosted on Microsoft [Azure](https://portal.azure.com). See `README.md` pre-requisites section for more information on how to set this up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Set parameters for Azure openai\n",
    "openai_rg_name = 'openai-lab'\n",
    "openai_svc_name = 'openai-lab-rm'\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = \"2023-03-15-preview\"\n",
    "\n",
    "# Choose your openai endpoint and key that you acquire when setting up Azure openai. I have set them as environment variables by using a .env-file.\n",
    "openai.api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Define the model for summarizing CV documents. I have used an old name, but the model is in fact gpt-35-turbo.\n",
    "text_summarization_model = \"text-davinci-003\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CV documents are rather lengthy and often contains repeated information and are formatted as a selling text. Some of that text can act a a disturbing noise for the LLM-models that will interpret and transform the data. Since these models don't care about how nicely and well formatted the document is, we can summarize the documents to make them as information dense and to-the-point as possible. By doing so we also decrease the length, making them easier and cheaper for the GPT-based models to process.\n",
    "\n",
    "For the model to produce (hopefully) good results, we set the context by informing it of the current situation and task at hand. We also set some tuneable parameters in our call to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-81Vt1tGVY2WCVg0aBTL5GjqrB8ICn\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1695371591,\n",
      "  \"model\": \"gpt-35-turbo\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"Richard Martin is a Data Scientist and consultant at Sopra Steria Sweden, where he specializes in building AI-driven analytics solutions. He works with a diverse team of consultants covering the entire field of data and analytics. Richard has several years of experience working with common tools such as Python, SQL, and Power BI. He is also proficient in statistics, business intelligence, and classical machine learning. Richard prefers to work in the Azure cloud ecosystem.\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 88,\n",
      "    \"prompt_tokens\": 147,\n",
      "    \"total_tokens\": 235\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Create a function that takes a CV and summarizes in and returns the summary\n",
    "def get_summary(document):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=text_summarization_model,\n",
    "        \n",
    "        # Here we set the context for the model to prepare it for the task\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a large language model specialized in summarizing CV documents. You do this by extracting all the information in a document that is relevant from a career and job application perspective.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Write a detailed summary of the CV document below: \\n\\n{document}\"}\n",
    "        ],\n",
    "        \n",
    "        # Here we set the model parameters which are used to tweak how the response turns out\n",
    "        temperature=0.2,\n",
    "        top_p=1,\n",
    "        n=1,\n",
    "        )\n",
    "    \n",
    "    return response\n",
    "\n",
    "\n",
    "# Test the model\n",
    "doc = \"Richard Martin is a consultant that specializes in building AI-driven analytics solutions. He works at Sopra Steria Sweden together with a diverse team of consultants covering the whole field of data and analytics. His job title is typically Data Scientist. He also works with statistics, business intelligence, and classical machine learning. He has several years of experience from common tools like Python, SQL and Power BI. He likes to work in the Azure cloud ecosystem.\"\n",
    "print(get_summary(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work with a small sample when developing\n",
    "data = raw.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "887c5fcefb484e3d973a1fd1544c6ea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summarize all documents\n",
    "data['summarization'] = ''\n",
    "for idx, category, cv in tqdm(zip(data.index.values, data['Category'].loc[data.index.values], data['cv'].loc[data.index.values]), total=len(data)):\n",
    "    \n",
    "    response = get_summary(cv)\n",
    "    data['summarization'].loc[idx] = response['choices'][0]['message']['content']\n",
    "\n",
    "# Newlines can cause problems when we create embeddings of the summarized documents, so we replace them with blank spaces.\n",
    "data['summarization'].replace(r'\\n',' ', regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>cv</th>\n",
       "      <th>summarization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10289</th>\n",
       "      <td>Arts</td>\n",
       "      <td>â¢ Operating Systems: Windows XP / Vista / 07...</td>\n",
       "      <td>The candidate has experience in operating syst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9160</th>\n",
       "      <td>ETL Developer</td>\n",
       "      <td>Education Details \\r\\nJanuary 2015 Bachelor of...</td>\n",
       "      <td>The candidate holds a Bachelor of Engineering ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10514</th>\n",
       "      <td>Java Developer</td>\n",
       "      <td>Computer Skills: Languages And Script: JSP, Se...</td>\n",
       "      <td>The candidate has computer skills in JSP, Serv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7224</th>\n",
       "      <td>Advocate</td>\n",
       "      <td>Education Details \\r\\n LLB.   Dibrugarh Univer...</td>\n",
       "      <td>The candidate's CV states that they have compl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5842</th>\n",
       "      <td>DevOps Engineer</td>\n",
       "      <td>CORE COMPETENCIES ~ Ant ~ Maven ~ GIT ~ Bitbuc...</td>\n",
       "      <td>The CV belongs to a DevOps Engineer with exper...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Category                                                 cv  \\\n",
       "10289             Arts  â¢ Operating Systems: Windows XP / Vista / 07...   \n",
       "9160     ETL Developer  Education Details \\r\\nJanuary 2015 Bachelor of...   \n",
       "10514   Java Developer  Computer Skills: Languages And Script: JSP, Se...   \n",
       "7224          Advocate  Education Details \\r\\n LLB.   Dibrugarh Univer...   \n",
       "5842   DevOps Engineer  CORE COMPETENCIES ~ Ant ~ Maven ~ GIT ~ Bitbuc...   \n",
       "\n",
       "                                           summarization  \n",
       "10289  The candidate has experience in operating syst...  \n",
       "9160   The candidate holds a Bachelor of Engineering ...  \n",
       "10514  The candidate has computer skills in JSP, Serv...  \n",
       "7224   The candidate's CV states that they have compl...  \n",
       "5842   The CV belongs to a DevOps Engineer with exper...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform into embeddings\n",
    "\n",
    "Embedding is a way to translate written text into structured numerical data. It is a mapping from string to array like so:\n",
    "`hi there' -> [0.1244, 0.1984, 0.1851]`\n",
    "\n",
    "The point of embedding the texts is that numerical arrays (vectors) are easier to compare for similarity than written text. Exactly how the transformation is done is hard to figure out since the model is kind of 'black box' by nature. But Microsoft explains it like this:\n",
    "> The embedding is an information dense representation of the semantic meaning of a piece of text\n",
    "\n",
    "![Picture of the embedding process](embed.png)\n",
    "\n",
    "We select a different GPT-model specialized for text-embedding, and create a funtion that embeds a text into a numerical vector. Then we proceed to process our dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding: [-0.01314186  0.00399883  0.01619395 ...  0.00137543 -0.01616747\n",
      " -0.01071873]\n",
      "Datatype of embedding: <class 'numpy.ndarray'>\n",
      "Length of embedding vector: 1536\n"
     ]
    }
   ],
   "source": [
    "# Select our deployed model specialized for embedding\n",
    "embedding_model = 'text-similarity-davinci-001'\n",
    "\n",
    "# Function for creating an embedding from a text\n",
    "def get_embedding(text, deployment_id):\n",
    "\n",
    "    result = openai.Embedding.create(\n",
    "      deployment_id=deployment_id,\n",
    "      input=text\n",
    "    )\n",
    "    result = np.array(result[\"data\"][0][\"embedding\"])\n",
    "    return result\n",
    "\n",
    "# Try it out\n",
    "embedding = get_embedding(\"What does the embedding of this sentence look like?\", embedding_model)\n",
    "\n",
    "# Check the results\n",
    "print('Embedding:', embedding)\n",
    "print('Datatype of embedding:', type(embedding))\n",
    "print('Length of embedding vector:', len(embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efddb53d6f204731a02ac47cd14a7dff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create embeddings for each CV in our dataset\n",
    "data['embedding'] = ''\n",
    "for i in tqdm(data.index.values):\n",
    "    try:\n",
    "        embedding = get_embedding(data['summarization'][i], embedding_model)\n",
    "        data['embedding'][i] = embedding\n",
    "    except Exception as err:\n",
    "        i\n",
    "        print(f\"Unexpected {err=}, {type(err)=}\")\n",
    "\n",
    "    # Wait between calls because of restrictions in model API\n",
    "    time.sleep(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>cv</th>\n",
       "      <th>summarization</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5842</th>\n",
       "      <td>DevOps Engineer</td>\n",
       "      <td>CORE COMPETENCIES ~ Ant ~ Maven ~ GIT ~ Bitbuc...</td>\n",
       "      <td>The CV belongs to a DevOps Engineer with exper...</td>\n",
       "      <td>[-0.002695744391530752, -0.022219469770789146,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9160</th>\n",
       "      <td>ETL Developer</td>\n",
       "      <td>Education Details \\r\\nJanuary 2015 Bachelor of...</td>\n",
       "      <td>The candidate holds a Bachelor of Engineering ...</td>\n",
       "      <td>[0.000728837912902236, -0.015829650685191154, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10289</th>\n",
       "      <td>Arts</td>\n",
       "      <td>â¢ Operating Systems: Windows XP / Vista / 07...</td>\n",
       "      <td>The candidate has experience in operating syst...</td>\n",
       "      <td>[0.005620994139462709, -0.004112922586500645, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10514</th>\n",
       "      <td>Java Developer</td>\n",
       "      <td>Computer Skills: Languages And Script: JSP, Se...</td>\n",
       "      <td>The candidate has computer skills in JSP, Serv...</td>\n",
       "      <td>[0.006072777323424816, -0.006378600373864174, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7224</th>\n",
       "      <td>Advocate</td>\n",
       "      <td>Education Details \\r\\n LLB.   Dibrugarh Univer...</td>\n",
       "      <td>The candidate's CV states that they have compl...</td>\n",
       "      <td>[-0.01249951682984829, -0.0009597481694072485,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Category                                                 cv  \\\n",
       "5842   DevOps Engineer  CORE COMPETENCIES ~ Ant ~ Maven ~ GIT ~ Bitbuc...   \n",
       "9160     ETL Developer  Education Details \\r\\nJanuary 2015 Bachelor of...   \n",
       "10289             Arts  â¢ Operating Systems: Windows XP / Vista / 07...   \n",
       "10514   Java Developer  Computer Skills: Languages And Script: JSP, Se...   \n",
       "7224          Advocate  Education Details \\r\\n LLB.   Dibrugarh Univer...   \n",
       "\n",
       "                                           summarization  \\\n",
       "5842   The CV belongs to a DevOps Engineer with exper...   \n",
       "9160   The candidate holds a Bachelor of Engineering ...   \n",
       "10289  The candidate has experience in operating syst...   \n",
       "10514  The candidate has computer skills in JSP, Serv...   \n",
       "7224   The candidate's CV states that they have compl...   \n",
       "\n",
       "                                               embedding  \n",
       "5842   [-0.002695744391530752, -0.022219469770789146,...  \n",
       "9160   [0.000728837912902236, -0.015829650685191154, ...  \n",
       "10289  [0.005620994139462709, -0.004112922586500645, ...  \n",
       "10514  [0.006072777323424816, -0.006378600373864174, ...  \n",
       "7224   [-0.01249951682984829, -0.0009597481694072485,...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our processed dataset ready for comparisons whenever we want to find candidates for a new job ad.\n",
    "This is a good time to store our data so that we dont have to re-process it each time we use our matching tool. In this example we simply save the results to a csv-file, but in a \"real\" environment it would typically be stored in a database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving numerical arrays inside a csv-file can be done by pickling the arrays.\n",
    "data['embedding'] = data['embedding'].apply(lambda arr: pickle.dumps(arr))\n",
    "\n",
    "# Save the results to our data folder\n",
    "data.to_csv(base_path+'embeddings.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build pipeline for transforming and comparing a job ad with the processed CVs\n",
    "We now define some functions that automates the process of reading in job ads and processing them in the same way as with our CV documents and then compares each one of them with the job ad to find the best matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the embeddings from our storage\n",
    "data = pd.read_csv(base_path+'embeddings.csv')\n",
    "\n",
    "# De-pickle the embeddings back into numpy arrays\n",
    "data['embedding'] = data['embedding'].apply(lambda pickled_arr: pickle.loads(eval(pickled_arr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We measure the similarity between two texts by measuring the angle between their respective embedding vectors. Since our embedding model strictly produces vectors of unit length, this is the same as taking the dot product between the vectors.\n",
    "def vector_similarity(x, y):\n",
    "    \"\"\"\n",
    "    Returns the similarity between two vectors.    \n",
    "    Because OpenAI Embeddings are normalized to length 1, the cosine similarity is the same as the dot product.\n",
    "    \"\"\"\n",
    "    similarity = np.dot(x, y)\n",
    "    return similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also want to sort the results in order of similarity score\n",
    "def order_document_sections_by_query_similarity(query, contexts):\n",
    "    \"\"\"\n",
    "    Find the query embedding for the supplied query, and compare it against all of the pre-calculated document embeddings\n",
    "    to find the most relevant candidates. \n",
    "    Return the list of articles, sorted by relevance in descending order.\n",
    "    \"\"\"\n",
    "    query_embedding = get_embedding(query, embedding_model)\n",
    "\n",
    "    document_similarities = sorted(\n",
    "        [(vector_similarity(query_embedding, doc_embedding), doc_index) for doc_index, doc_embedding in contexts.items()], \n",
    "        reverse=True)\n",
    "    \n",
    "    return document_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally we need a function that processes our dataset by using the above functions and return our final result\n",
    "def retrieve_relevant_documents(description, data, top_n=5):\n",
    "    \n",
    "    # find text most similar to the query\n",
    "    answers = order_document_sections_by_query_similarity(query=description, contexts=data['embedding'])[0:top_n]\n",
    "    results = []\n",
    "\n",
    "    # print top n\n",
    "    for answer in answers:\n",
    "        name = 'name' #data[\"namn\"].loc[answer[1]]\n",
    "        idx = answer[1]\n",
    "        score = answer[0]\n",
    "        summarization = data['summarization'].loc[answer[1]]\n",
    "        results.append({'id': idx, 'score': score, 'summarization': summarization})\n",
    "\n",
    "        print(f'id:   {idx},   similarity score:   {score}')\n",
    "        print(summarization, '\\n')\n",
    "\n",
    "    return results, answers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, we feed our model a sample job ad and see the summarized CVs returned along with a similarity score for each och the matches. Here we limit the response to the top _n_ matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id:   2,   similarity score:   0.787698408453656\n",
      "The candidate has computer skills in JSP, Servlet, HTML, CSS, JavaScript, jQuery, Ajax, Spring, Hibernate, MySQL, Eclipse, and NetBeans IDE. They have education in H.S.C from VidyaBharati college in Amravati, Maharashtra in January 2007 and S.S.C from Holy Cross English School in Amravati, Maharashtra in January 2005. They have worked as a Java Developer for 14 months and have experience in Eclipse, Hibernate, Spring, and jQuery. They are currently working as a Java Developer in Winsol Solution Pvt Ltd since July 2017 and have a total of 2 years of experience as a Java Developer in Kunal IT Services Pvt Ltd. \n",
      "\n",
      "id:   4,   similarity score:   0.7628761191639152\n",
      "The CV belongs to a DevOps Engineer with experience in deployment, documentation, change management, and configuration management. The candidate has hands-on experience in DevOps, automation, build engineering, and configuration management. They have worked on multiple projects involving different development teams and multiple simultaneous software releases. The candidate has experience in creating fully automated CI build and deployment infrastructure and processes for multiple projects using tools such as Git, Bitbucket, Jenkins, Ansible, and Shell Scripting. They have also developed Ant, Maven, and Shell scripts to automatically compile, package, and deploy WAR, EAR, and JAR files of multiple applications to various platforms. The candidate has experience in resolving build issues, collaborating with development, QA, and product management teams on build plans and schedules, and maintaining Maven and shell scripts for safe builds and deploys. They have also created and maintained documentation of build and release processes and application configuration. \n",
      "\n",
      "id:   1,   similarity score:   0.7514880934158673\n",
      "The candidate holds a Bachelor of Engineering in EXTC from Mumbai University and a Diploma in Industrial Electronics from Fr. Agnel Polytechnic. They have 36 months of experience as an ETL Developer with expertise in Informatica. They worked at Blue Shield of California from March 2016 to September 2017, where they were responsible for analyzing business requirements, developing Informatica mappings, writing Unix scripts and SQL queries, and troubleshooting existing bugs. They also received awards and recognition for their contribution to error-free work, commitment towards learning, client appreciation, and outstanding performance. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = 'Vi söker en medarbetare till vår bid avdelning. Personen ska kunna arbeta med bid- och anbudsprocesser och sköta intervjuer med kunder och egna konsulter. God kommunikationsförmåga är av yttersta vikt. CSS, JavaScript, jQuery, Ajax.'\n",
    "results, answers = retrieve_relevant_documents(description=query, data=data, top_n=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "job-cv-matching",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
